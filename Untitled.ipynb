{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054b5d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfminer.high_level as hl\n",
    "import re\n",
    "\n",
    "def extract_resume_data(pdf_file):\n",
    "    '''\n",
    "    Extracts data from a PDF resume file.\n",
    "\n",
    "      Args:\n",
    "        pdf_file: The path to the PDF file.\n",
    "\n",
    "      Returns:\n",
    "        A dictionary containing the extracted data.\n",
    "    '''\n",
    "\n",
    "    resume_data = {}\n",
    "\n",
    "    # Extract the text from the PDF file.\n",
    "    with open(pdf_file, \"rb\") as f:\n",
    "        text = hl.extract_text(f)\n",
    "\n",
    "    # Identify the relevant sections of the resume.\n",
    "    skills_section_index = text.find(\"Skills\")\n",
    "    education_section_index = text.find(\"Education\")\n",
    "    experience_section_index = text.find(\"Experience\")\n",
    "    print(skills_section_index)\n",
    "\n",
    "    # Extract the desired information from each section.\n",
    "\n",
    "#     # Job role\n",
    "#     job_role = re.search(r\"Job Role:\\s+(\\w+\\s+\\w+)\", text).group(1)\n",
    "\n",
    "#     # Educational qualifications\n",
    "#     education_qualifications = []\n",
    "#     for line in text[education_section_index + 1:].split(\"\\n\"):\n",
    "#         if line.strip() == \"\":\n",
    "#           break\n",
    "#         else:\n",
    "#           education_qualifications.append(line)\n",
    "\n",
    "    # Skills\n",
    "    skills = []\n",
    "    for line in text[skills_section_index + 1:].split(\"\\n\"):\n",
    "        if line.strip() == \"\":\n",
    "          break\n",
    "        else:\n",
    "          skills.append(line)\n",
    "\n",
    "#     # Experience\n",
    "#     experience = []\n",
    "#     for line in text[experience_section_index + 1:].split(\"\\n\"):\n",
    "#         if line.strip() == \"\":\n",
    "#           break\n",
    "#         else:\n",
    "#           experience.append(line)\n",
    "\n",
    "#     # Add the extracted data to the resume_data dictionary.\n",
    "#     resume_data[\"job_role\"] = job_role\n",
    "#     resume_data[\"education_qualifications\"] = education_qualifications\n",
    "    resume_data[\"skills\"] = skills\n",
    "#     resume_data[\"experience\"] = experience\n",
    "\n",
    "    return resume_data\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "pdf_file = os.path.join(os.getcwd(),\"archive\\data\\data\\INFORMATION-TECHNOLOGY/10089434.pdf\")\n",
    "resume_data = extract_resume_data(pdf_file)\n",
    "\n",
    "print(resume_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d643db8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "root_directory = os.path.join(os.getcwd(),'archive/data')\n",
    "\n",
    "# Use os.walk to traverse through all directories and files\n",
    "for root, directories, files in os.walk(root_directory):\n",
    "#     print(root)\n",
    "#     print(directories)\n",
    "#     print(files)\n",
    "        for filename in files:\n",
    "            # Construct the full path of the file\n",
    "            file_path = os.path.join(root, filename)\n",
    "#             print(file_path)\n",
    "            # Example usage:\n",
    "            resume_data = extract_resume_data(file_path)\n",
    "\n",
    "            print(resume_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7b7cc33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\SimpliLearn\\NLP\\NLP\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import LongformerTokenizer, LongformerModel,LongformerForSequenceClassification\n",
    "\n",
    "class SkillClassifier(torch.nn.Module):\n",
    "  def __init__(self):\n",
    "    super(SkillClassifier, self).__init__()\n",
    "\n",
    "    # Load the Longformer model.\n",
    "    self.bert = LongformerModel.from_pretrained(\"allenai/longformer-base-4096\")\n",
    "\n",
    "    # Define the classifier.\n",
    "    self.classifier = torch.nn.Linear(4096, 2)\n",
    "\n",
    "  def forward(self, input_ids, attention_mask):\n",
    "    # Get the Longformer embeddings.\n",
    "    bert_embeddings = self.bert(input_ids, attention_mask)[0]\n",
    "    bert_embeddings = bert_embeddings.squeeze(1)\n",
    "    # Classify the Longformer embeddings as skills or not skills.\n",
    "    logits = self.classifier(bert_embeddings)\n",
    "    predictions = torch.sigmoid(logits)\n",
    "\n",
    "    return predictions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af659396",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BartTokenizer, BartForConditionalGeneration\n",
    "\n",
    "def summarize_text_using_BART(text, max_length=512):\n",
    "    \"\"\"Summarizes a text using BERT.\n",
    "\n",
    "    Args:\n",
    "        text: The text to be summarized.\n",
    "        max_length: The maximum length of the summarized text.\n",
    "\n",
    "    Returns:\n",
    "        A summarized version of the text.\n",
    "    \"\"\"\n",
    "\n",
    "    # Tokenize the text.\n",
    "    tokenizer = BartTokenizer.from_pretrained(\"facebook/bart-large-cnn\")\n",
    "    tokens = tokenizer(text, return_tensors=\"pt\")\n",
    "\n",
    "    # Generate a summary of the text.\n",
    "    model = BartForConditionalGeneration.from_pretrained(\"facebook/bart-large-cnn\")\n",
    "    summary = model.generate(input_ids=tokens[\"input_ids\"], attention_mask=tokens[\"attention_mask\"], max_length=max_length)\n",
    "\n",
    "    # Decode the summary.\n",
    "    decoded_summary = tokenizer.decode(summary[0])\n",
    "\n",
    "    return decoded_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f3599d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfminer.high_level as hl\n",
    "from transformers import LongformerModel, LongformerTokenizer\n",
    "def extract_skills_from_resume(resume):\n",
    "    \"\"\"Extracts skills from a resume using BERT.\n",
    "\n",
    "    Args:\n",
    "    resume: The resume text.\n",
    "\n",
    "    Returns:\n",
    "    A list of skills extracted from the resume.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Tokenize the resume.\n",
    "    tokenizer = LongformerTokenizer.from_pretrained(\"allenai/longformer-base-4096\")\n",
    "    tokens = tokenizer(resume ,return_tensors=\"pt\")\n",
    "#     print(len(tokens['input_ids'][0]))\n",
    "#     if len(tokens['input_ids'][0]) > 512:\n",
    "#         resume = summarize_text_using_BART(resume,512)\n",
    "#         skills = extract_skills_from_resume(resume)\n",
    "#         return skills\n",
    "        \n",
    "        \n",
    "\n",
    "    # Convert the tokens to BERT embeddings.\n",
    "    model = LongformerModel.from_pretrained(\"allenai/longformer-base-4096\")\n",
    "    embeddings = model(tokens[\"input_ids\"], attention_mask=tokens[\"attention_mask\"])[0]\n",
    "\n",
    "    # Classify the BERT embeddings as skills or not skills.\n",
    "    classifier = SkillClassifier()\n",
    "    predictions = classifier(input_ids=tokens[\"input_ids\"], attention_mask=tokens[\"attention_mask\"])\n",
    "\n",
    "    # Extract the skills from the predictions.\n",
    "    skills = []\n",
    "#     print(predictions)\n",
    "#     skills = predictions\n",
    "    for i in range(len(predictions[0])):\n",
    "        if predictions[0][i] > 0.5:\n",
    "          skills.append(tokenizer.decode([tokens[\"input_ids\"][0][i]]))\n",
    "\n",
    "    return skills\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "909a6ebb",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (1763x768 and 4096x2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(pdf_file, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m      4\u001b[0m         resume \u001b[38;5;241m=\u001b[39m hl\u001b[38;5;241m.\u001b[39mextract_text(f)\n\u001b[1;32m----> 5\u001b[0m resume_data \u001b[38;5;241m=\u001b[39m \u001b[43mextract_skills_from_resume\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresume\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# extract_skills_from_resume(resume)\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# print(resume_data)\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[3], line 30\u001b[0m, in \u001b[0;36mextract_skills_from_resume\u001b[1;34m(resume)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Classify the BERT embeddings as skills or not skills.\u001b[39;00m\n\u001b[0;32m     29\u001b[0m classifier \u001b[38;5;241m=\u001b[39m SkillClassifier()\n\u001b[1;32m---> 30\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mclassifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokens\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput_ids\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokens\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mattention_mask\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# Extract the skills from the predictions.\u001b[39;00m\n\u001b[0;32m     33\u001b[0m skills \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32mD:\\SimpliLearn\\NLP\\NLP\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn[1], line 19\u001b[0m, in \u001b[0;36mSkillClassifier.forward\u001b[1;34m(self, input_ids, attention_mask)\u001b[0m\n\u001b[0;32m     17\u001b[0m bert_embeddings \u001b[38;5;241m=\u001b[39m bert_embeddings\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Classify the Longformer embeddings as skills or not skills.\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclassifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbert_embeddings\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m predictions \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msigmoid(logits)\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m predictions\n",
      "File \u001b[1;32mD:\\SimpliLearn\\NLP\\NLP\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mD:\\SimpliLearn\\NLP\\NLP\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (1763x768 and 4096x2)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "pdf_file = os.path.join(os.getcwd(),\"archive\\data\\data\\INFORMATION-TECHNOLOGY/10089434.pdf\")\n",
    "with open(pdf_file, \"rb\") as f:\n",
    "        resume = hl.extract_text(f)\n",
    "resume_data = extract_skills_from_resume(resume)\n",
    "# extract_skills_from_resume(resume)\n",
    "\n",
    "# print(resume_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b65c6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(resume_data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319ae243",
   "metadata": {},
   "outputs": [],
   "source": [
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816af878",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

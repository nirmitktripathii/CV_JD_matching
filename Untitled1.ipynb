{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb13c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import BertTokenizer, BertModel\n",
    "\n",
    "# # Initialize BERT model and tokenizer\n",
    "# bert_model_name = \"bert-base-uncased\"\n",
    "# bert_tokenizer = BertTokenizer.from_pretrained(bert_model_name)\n",
    "# bert_model = BertModel.from_pretrained(bert_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b98710ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfminer.high_level as hl\n",
    "import os\n",
    "from pdfminer.layout import LTTextContainer\n",
    "import contractions\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk_stopwords = set(stopwords.words('english'))\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "\n",
    "# Convert the frozen set to a list\n",
    "sklearn_stopwords = set(ENGLISH_STOP_WORDS)\n",
    "\n",
    "# Combining the stopwords form sklearn & NLTK\n",
    "combined_stopwords = sklearn_stopwords.union(nltk_stopwords)\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    \"\"\"Extracts the text from a PDF file.\n",
    "\n",
    "    Args:\n",
    "    pdf_path: The path to the PDF file.\n",
    "\n",
    "    Returns:\n",
    "    A string containing the text from the PDF file.\n",
    "    \"\"\"\n",
    "\n",
    "#   with open(pdf_path, \"rb\") as f:\n",
    "#     doc = hl.extract_text(f)\n",
    "     #Substituting contractions\n",
    "  \n",
    "    with open(pdf_file, \"rb\") as f:\n",
    "            resume = hl.extract_text(f)\n",
    "                \n",
    "#     print(resume)\n",
    "\n",
    "        \n",
    "        \n",
    "    cleaned_text = contractions.fix(resume)\n",
    "\n",
    "    # User-mentions Removal\n",
    "    cleaned_text = re.sub(\"@[A-Za-z0-9]+\", \"\", cleaned_text)\n",
    "\n",
    "    # Hashtag Removal\n",
    "    cleaned_text = re.sub(\"#\", \"\", cleaned_text)\n",
    "\n",
    "    #Hyperlink Removal\n",
    "    cleaned_text = re.sub(r\"http\\S+\",\"\", cleaned_text)\n",
    "\n",
    "    # Punctuation, Special Characters and digits Removal (Retaining only the alphabets)\n",
    "#     cleaned_text = re.sub(r\"[^a-zA-Z]\", \" \" , cleaned_text )\n",
    "\n",
    "    # convert the tweet into lowercase & get rid of any leading or trailing spaces\n",
    "    cleaned_text = cleaned_text.lower().strip()\n",
    "    \n",
    "     #remove stopwords from the new_sent\n",
    "    cleaned_tokens = [token for token in cleaned_text.split() if token not in combined_stopwords]\n",
    "\n",
    "    # Retain only those token which have length > 2 characters\n",
    "    cleaned_tokens = [token for token in cleaned_tokens if len(token)>2]\n",
    "\n",
    "    new_sent = ''\n",
    "    for token in cleaned_tokens:\n",
    "        new_sent = new_sent + token + ' '\n",
    "\n",
    "    return new_sent\n",
    "\n",
    "    \n",
    "\n",
    "#     text_content.append(content)\n",
    "\n",
    "#   return \"\\n\".join(text_content)\n",
    "\n",
    "\n",
    "pdf_file = os.path.join(os.getcwd(),\"archive\\data\\data\\INFORMATION-TECHNOLOGY/10089434.pdf\")\n",
    "\n",
    "resume_text = extract_text_from_pdf(pdf_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fb0ac24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'information technology technician summary versatile systems administrator possessing superior troubleshooting skills networking issues end user problems network security experienced server management systems analysis offering depth understanding infrastructure areas oriented independent focused taking systematic approach solving complex problems demonstrated exceptional technical knowledge skills working various teams achieve shared goals objectives highlights active directory group policy objects powershell vbscript microsoft exchange vmware experience new technology product research office azure storage management enterprise backup management disaster recovery experience information technology technician aug current company city state migrating managing user accounts microsoft office exchange online creating managing virtual machines systems domain controllers active directory federation services adfs microsoft windows azure iaas creating managing storage microsoft windows azure iaas installing configuring storsimple iscsi cloud array staas baas installing configuring testing twinstrata iscsi cloud array staas baas collaborating project plan office migration developing detailed specifications office migration including business case documentation cost benefit analyses technical diagrams work flow documentation received training mvc visual studio using net framework develop application using html css installing configuring supporting linux machines open network project compiling generating statistical information concerning wireless network traffic using cacti configuring wireless lan router networking security access installing configuring wireless certificates developing detailed specifications acquisition enterprise backup including systems design business case documentation cost benefit analysis technical diagrams work flow documentation reviewing evaluating analyzing departmental policies guidelines procedures standards management staff developing test scripts acceptance unit testing hyperion phase miamibiz phase developing quality assurance testing plan hyperion phase miamibiz phase debugging logging errors hyperion miamibiz using team foundation server tfs participated various phases project life cycle determining requirements design conceptualization testing implementation deployment release hyperion miamibiz projects collaborating project plans hyperion miamibiz preparing presentations documentation demonstrate hyperion miamibiz functionality design monitoring network traffic compiling generating statistical information using solar winds collaborating disaster recovery plan procedures researching evaluating recommending new hardware new software communicating defining systems design requirements new existing systems applications researching evaluating recommending testing implementing party software utilities planning designing network infrastructure changes adding removing servers appliances network logical flow reviewing evaluating analyzing existing application viability management staff administering maintaining shares file servers reviewing server logs troubleshoot issues scheduling applying hot fixes security patches server infrastructure includes operating application software reviewing systems reporting sccm center configuration manager resolving service requests escalated help desk technicians troubleshooting analyzing problems root analysis giving participating training education programs explain upgrades end users migrating users documents local computer storage shares file servers configuring supporting maintaining file shares using distributed file dfs managing implementing testing enterprise backup infrastructure systems symantec veritas netbackup symantec backup exec recovery livestate vranger backup servers managing configuring supporting datadomain storage configuring supporting microsoft windows server installing configuring supporting microsoft windows windows microsoft office installing configuring supporting mcafee anti virus software servers migrating exchange infrastructure exchange exchange exchange exchange supporting servers virtualization infrastructure using vmware vsphere installing configuring testing veeam virtual machine backup software virtual desktop infrastructure vdi reviewing systems reporting center configuration manager sccm administering maintaining symantec enterprise vault servers managing active directory domain controllers dcs creating maintaining group policy objects gpos microsoft active directory configuring supporting microsoft exchange active sync devices apple ios android mobile operating systems configuring supporting blackberry devices blackberry enterprise server receive exchange email developing testing designing implementing application scripts using languages command batch files visual basic script powershell creating policies procedural documentation information services liaison aug aug company city state troubleshooting hardware software problems telephone remote administration software installing configuring supporting mcafee anti virus software desktops installing configuring supporting bbars computer backup software developing maintaining websites servers running microsoft sharepoint server internet information services iis supporting systems management server sms troubleshooting lan wan internet intranet network security access troubleshooting network connectivity issues related tcp domain service dns dynamic host configuration protocol dhcp protocols internet security acceleration isa proxy server vpn troubleshooting web application page issues client browsers related software administering maintaining end user accounts permissions access rights microsoft active directory administering maintaining ntfs security permissions file servers installing configuring maintaining hardware servers workstations laptops printers scanners windows enterprise environment installing configuring supporting printers print servers installing configuring supporting microsoft windows server microsoft windows windows vista microsoft office education bachelor science information technology florida international univeristy city state united states coursework programming web administration network administration database administration systems administration linux programming languages java jsp html css net bash sql certifications comptia network skills active directory azure anti virus backup exec backup bash batch cacti cisco asa databases dhcp dns documentation datadomain emc enterprise vault epo file servers firewall gpo html iis isa ldap linux mcafee exchange microsoft office microsoft windows security policies powershell programming proxy server servers scripts solarwinds sql storsimple troubleshooting tmg ubuntu visual basic script vbs veritas netbackup vpn vranger veeam vmware vdi virtual manchine nmap zenmap'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resume_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c5e36e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\SimpliLearn\\NLP\\NLP\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Potential Skills: ['configur configur configur configur configurbu', 'technician i summary versatile administrator possessing superiorhooting skills for experienced in offering in - depth understanding of areas - oriented independent focused on taking a systematic approach to solving demonstrated exceptional technical knowledge skills while working with various teams to achieve shared highlights experience new experience technician current received training with staff participated various', 'migrating managing creating managing creating managing installinging installinging testing collaborating developing including develop installinging supporting compiling generatinging installinging developing reviewing evaluating analyzing developing test testing developing testinggging logging using determining designization testing implementation deployment release', 'technology systems troubles issues end user problems security management systems detail complex problems policy technology product technology project business case cost benefit technical work flow statistical business case cost benefit technical work flow quality project', 'information networking network server it infrastructure active directory grouphell vcript exchange vware storage management enterprise backup management disaster recovery information user accounts exchange online virtual machines systems domain controllers active directory federation services storage cloud array cloud array migration migration application html machines open wi fi network wireless network traffic wireless lan router networking security access wireless certificates acquisition enterprise backup system systems departmental management acceptance unit systemionion errorsion team foundation serverion', 'hyper miami hyper miami hyper miami hyper miami', '.......................', 'and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and', ',,,,,,,,,,,,,,,,,,,,,,,,', '[CLS]m i aug 2007 to company name i¼ city state in for such as ( in ( in ( ) ( / ( / on for for the - in mvc 4 for studio using. framework 4 / 4 5 to using53 for the - project concerning using for the of an including - for of 1 2 for 1 2 de of in ( in of the life cycle such as : for the [SEP]', 'microsoft office 365 azure microsoft office 365 microsoft windows azure microsoft windows azure office 365 office 365 visual net linux', 'powersbs adfs iaas iaas storsimple iscsi staas baas twinstrata iscsi staas baas css cactibizbizbiz tfsbiz', 'analysis goals objectives objects research plan detailed specifications documentation analyses diagrams documentation information detailed specifications design documentation analysis diagrams documentation policies guidelines procedures standards scripts assurance plan requirements conceptual projects', 'phase phase phase phase phases', ',,, ) ) ) ),,,, )']\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "\n",
    "# Load BERT model and tokenizer\n",
    "bert_model_name = \"bert-base-uncased\"\n",
    "tokenizer = BertTokenizer.from_pretrained(bert_model_name)\n",
    "model = BertModel.from_pretrained(bert_model_name)\n",
    "\n",
    "with open(pdf_file, \"rb\") as f:\n",
    "    resume_text = hl.extract_text(f)\n",
    "\n",
    "# Tokenize the resume\n",
    "tokens = tokenizer(resume_text, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "\n",
    "# Get BERT embeddings\n",
    "with torch.no_grad():\n",
    "    outputs = model(**tokens)\n",
    "\n",
    "# Extract BERT embeddings\n",
    "embeddings = outputs.last_hidden_state[0].numpy()\n",
    "\n",
    "# Apply K-means clustering to the embeddings\n",
    "num_clusters = 15  # You can adjust the number of clusters\n",
    "kmeans = KMeans(n_clusters=num_clusters, random_state=0).fit(embeddings)\n",
    "\n",
    "# Identify clusters as potential skills\n",
    "potential_skills = []\n",
    "\n",
    "for cluster_id in range(num_clusters):\n",
    "    cluster_tokens = np.array(tokens[\"input_ids\"][0])[kmeans.labels_ == cluster_id]\n",
    "    cluster_text = tokenizer.decode(cluster_tokens)\n",
    "    potential_skills.append(cluster_text)\n",
    "\n",
    "# Print the potential skills\n",
    "print(\"Potential Skills:\", potential_skills)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df38dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca71ce48",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = bert_model(tokens[\"input_ids\"], attention_mask=tokens[\"attention_mask\"])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585c43d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7afd1e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "skill_ids = generate_skills(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7b5653",
   "metadata": {},
   "outputs": [],
   "source": [
    "skill=[]\n",
    "for ids in skill_ids:\n",
    "    skill+=bert_tokenizer.decode(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019bac6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "skill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3604ce3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import contractions\n",
    "\n",
    "# def tweet_cleaner_with_stopwords(raw_tweet):\n",
    "#     '''\n",
    "#     This function cleans the raw tweet\n",
    "#     '''\n",
    "#     #Substituting contractions\n",
    "#     cleaned_tweet = contractions.fix(raw_tweet)\n",
    "\n",
    "#     # User-mentions Removal\n",
    "#     cleaned_tweet = re.sub(\"@[A-Za-z0-9]+\", \"\", cleaned_tweet)\n",
    "\n",
    "#     # Hashtag Removal\n",
    "#     cleaned_tweet = re.sub(\"#\", \"\", cleaned_tweet)\n",
    "\n",
    "#     #Hyperlink Removal\n",
    "#     cleaned_tweet = re.sub(r\"http\\S+\",\"\", cleaned_tweet)\n",
    "\n",
    "#     # Punctuation, Special Characters and digits Removal (Retaining only the alphabets)\n",
    "#     cleaned_tweet = re.sub(r\"[^a-zA-Z]\", \" \" , cleaned_tweet )\n",
    "\n",
    "#     # convert the tweet into lowercase & get rid of any leading or trailing spaces\n",
    "#     cleaned_tweet = cleaned_tweet.lower().strip()\n",
    "\n",
    "#     #remove stopwords from the new_sent\n",
    "#     cleaned_tokens = [token for token in cleaned_tweet.split() if token not in combined_stopwords]\n",
    "\n",
    "#     # Retain only those token which have length > 2 characters\n",
    "#     cleaned_tokens = [token for token in cleaned_tokens if len(token)>2]\n",
    "\n",
    "#     new_sent = ''\n",
    "#     for token in cleaned_tokens:\n",
    "#         new_sent = new_sent + lemmatizer.lemmatize(token) + ' '\n",
    "\n",
    "#     return new_sent.strip()\n",
    "# # tokens = tokenizer(resume_text, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0128e94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "\n",
    "# Convert the frozen set to a list\n",
    "sklearn_stopwords = set(ENGLISH_STOP_WORDS)\n",
    "\n",
    "# Print the first few stopwords\n",
    "print(sklearn_stopwords)\n",
    "tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092b1f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = model(tokens[\"input_ids\"], attention_mask=tokens[\"attention_mask\"])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e676c631",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "ce9d0084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job Role: INFORMATION TECHNOLOGY TECHNICIAN I\n",
      "Education: \n",
      "Bachelor of Science , Information Technology 2005 Florida International Univeristy ï¼​ City , State , United States\n",
      "\n",
      "Skills: \n",
      "\n",
      "Active Directory, Azure, anti-virus, Backup Exec, backup, Bash, batch, Cacti, Cisco ASA, databases, DHCP, DNS, documentation,\n",
      "DataDomain, EMC, Enterprise Vault, ePO, file servers, firewall, GPO, HTML, IIS, ISA, LDAP, Linux, McAfee, Exchange, Microsoft Office,\n",
      "Microsoft Windows, security, policies, PowerShell, programming, proxy server, servers, scripts, SolarWinds, SQL, StorSimple, troubleshooting,\n",
      "TMG, Ubuntu, Visual Basic Script, VBS, Veritas Netbackup, VPN, VRanger, Veeam, VMWare, VDI, virtual manchine, NMap, ZenMap.\n",
      "\n",
      "\f",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Sample resume text\n",
    "pdf_file = os.path.join(os.getcwd(),\"archive\\data\\data\\INFORMATION-TECHNOLOGY/10089434.pdf\")\n",
    "with open(pdf_file, \"rb\") as f:\n",
    "        resume = hl.extract_text(f)\n",
    "\n",
    "# Regular expressions for skills extraction\n",
    "skills_pattern =  r\"Skills([\\s\\S]*?)(?=\\\\n\\\\n[Work])|Skills([\\s\\S]+)|Skills([\\s\\S]+?)(?=\\\\n\\\\n[Experience])|Skills([\\s\\S]+?)(?=\\\\n\\\\n[Education])\"\n",
    "education_pattern = r\"Education([\\s\\S]+?)(?=\\n[A-Z])\"\n",
    "category_pattern = r\"(\\b[A-Z\\s]+\\b)(?=\\n)\"\n",
    "\n",
    "skills_matches = re.finditer(skills_pattern, resume, re.MULTILINE | re.UNICODE | re.DOTALL)\n",
    "education_matches = re.finditer(education_pattern, resume, re.MULTILINE | re.UNICODE)\n",
    "category_matches = re.search(category_pattern, resume, re.MULTILINE | re.UNICODE)\n",
    "\n",
    "# Job Role Extraction:\n",
    "if category_matches:\n",
    "\n",
    "    for groupNum in range(0, len(category_matches.groups())):\n",
    "        groupNum = groupNum + 1\n",
    "        \n",
    "        print (f\"Job Role: {category_matches.group(groupNum)}\")\n",
    "\n",
    "# Latest Education Details Extraction\n",
    "for matchNum, match in enumerate(education_matches, start=1):\n",
    "        \n",
    "    for groupNum in range(0, len(match.groups())):\n",
    "        groupNum = groupNum + 1\n",
    "        \n",
    "        print (f\"Education: {match.group(groupNum)}\")\n",
    "        \n",
    "\n",
    "# Skills Extraction\n",
    "for matchNum, match in enumerate(skills_matches, start=1):\n",
    "    \n",
    "#     print (\"Match {matchNum} was found at {start}-{end}: {match}\".format(matchNum = matchNum, start = match.start(), end = match.end(), match = match.group()))\n",
    "    \n",
    "    for groupNum in range(0, len(match.groups())):\n",
    "        groupNum = groupNum + 1\n",
    "        if match.group(groupNum) is not None:\n",
    "            print (f\"Skills: {match.group(groupNum)}\")\n",
    "            skills = match.group(groupNum)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb713ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "resume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "acdd116c",
   "metadata": {},
   "outputs": [],
   "source": [
    "skills = skills.replace('\\n','').replace(' ','').replace('.\\x0c','').split(',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "daab7d7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ActiveDirectory',\n",
       " 'Azure',\n",
       " 'anti-virus',\n",
       " 'BackupExec',\n",
       " 'backup',\n",
       " 'Bash',\n",
       " 'batch',\n",
       " 'Cacti',\n",
       " 'CiscoASA',\n",
       " 'databases',\n",
       " 'DHCP',\n",
       " 'DNS',\n",
       " 'documentation',\n",
       " 'DataDomain',\n",
       " 'EMC',\n",
       " 'EnterpriseVault',\n",
       " 'ePO',\n",
       " 'fileservers',\n",
       " 'firewall',\n",
       " 'GPO',\n",
       " 'HTML',\n",
       " 'IIS',\n",
       " 'ISA',\n",
       " 'LDAP',\n",
       " 'Linux',\n",
       " 'McAfee',\n",
       " 'Exchange',\n",
       " 'MicrosoftOffice',\n",
       " 'MicrosoftWindows',\n",
       " 'security',\n",
       " 'policies',\n",
       " 'PowerShell',\n",
       " 'programming',\n",
       " 'proxyserver',\n",
       " 'servers',\n",
       " 'scripts',\n",
       " 'SolarWinds',\n",
       " 'SQL',\n",
       " 'StorSimple',\n",
       " 'troubleshooting',\n",
       " 'TMG',\n",
       " 'Ubuntu',\n",
       " 'VisualBasicScript',\n",
       " 'VBS',\n",
       " 'VeritasNetbackup',\n",
       " 'VPN',\n",
       " 'VRanger',\n",
       " 'Veeam',\n",
       " 'VMWare',\n",
       " 'VDI',\n",
       " 'virtualmanchine',\n",
       " 'NMap',\n",
       " 'ZenMap']"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7e713e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
